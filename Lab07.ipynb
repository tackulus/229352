{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab07.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOST6cJ+ErNHhdH9aVH/suG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tackulus/229352/blob/main/Lab07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUK5Xhf7y1cK"
      },
      "source": [
        "## **Lab 07**\n",
        "\n",
        "---\n",
        "\n",
        "> **229352 Statistical Learning for Data Science 2**\n",
        "\n",
        "> **Kasidis Torcharoen (610510531)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI-zVpcfxVHD"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "(X_train, y_train), _ = datasets.fashion_mnist.load_data()\n",
        "X_train = X_train / 255.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyhxq0IR3F7K"
      },
      "source": [
        "1. Build the neural network model \n",
        "\n",
        "2. Modify your model by adding some dropout, batch normalization or layer normalization layers. Trainyour model by calling model.fit on the training set with validationsplit=0.2. Play around with the layers and various hyperparameters (learning rate, batch size etc.) until the modelâ€™s validation accuracy exceeds 90%. Save your best model, and then turn it in along with your pdf report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKpjpO-Cx2jV"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "input = layers.Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
        "x = layers.Flatten()(input)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "a = layers.Dense(512, activation='relu')(x)\n",
        "a = layers.Dense(256, activation='relu')(a)\n",
        "a = layers.Dense(128, activation='relu')(a)\n",
        "a = layers.BatchNormalization()(a)\n",
        "\n",
        "b = layers.Dense(128, activation='relu')(x)\n",
        "b = layers.Dense(512, activation='relu')(b)\n",
        "b = layers.BatchNormalization()(b)\n",
        "\n",
        "x = layers.Concatenate()([a,b])\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(10, activation='softmax')(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC25YC5R37sg",
        "outputId": "e17daddd-a183-4c98-90be-ecb38485f601"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Model(inputs=input, outputs=output)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "            optimizer=Adam(learning_rate=0.001),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 784)          0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 784)          0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 512)          401920      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 256)          131328      dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 128)          100480      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 128)          32896       dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 512)          66048       dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128)          512         dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 512)          2048        dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 640)          0           batch_normalization_6[0][0]      \n",
            "                                                                 batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 64)           41024       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 10)           650         dense_26[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 776,906\n",
            "Trainable params: 775,626\n",
            "Non-trainable params: 1,280\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYpTj-Rx9cei",
        "outputId": "e54abf10-3830-4ea0-8758-2daf028a3405"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n",
        "                               patience=10,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train,y_train,\n",
        "          validation_split=0.2,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          callbacks=[early_stopping])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 0.5191 - accuracy: 0.8098 - val_loss: 0.4178 - val_accuracy: 0.8451\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.4069 - accuracy: 0.8500 - val_loss: 0.4532 - val_accuracy: 0.8368\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3772 - accuracy: 0.8592 - val_loss: 0.3784 - val_accuracy: 0.8652\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3549 - accuracy: 0.8674 - val_loss: 0.3647 - val_accuracy: 0.8674\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3390 - accuracy: 0.8725 - val_loss: 0.3653 - val_accuracy: 0.8702\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3276 - accuracy: 0.8759 - val_loss: 0.3409 - val_accuracy: 0.8731\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3131 - accuracy: 0.8818 - val_loss: 0.3337 - val_accuracy: 0.8771\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3063 - accuracy: 0.8840 - val_loss: 0.3212 - val_accuracy: 0.8810\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2990 - accuracy: 0.8867 - val_loss: 0.3171 - val_accuracy: 0.8818\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2881 - accuracy: 0.8902 - val_loss: 0.3203 - val_accuracy: 0.8800\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2827 - accuracy: 0.8913 - val_loss: 0.3302 - val_accuracy: 0.8772\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2776 - accuracy: 0.8952 - val_loss: 0.3329 - val_accuracy: 0.8798\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2694 - accuracy: 0.8966 - val_loss: 0.3048 - val_accuracy: 0.8903\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2677 - accuracy: 0.8979 - val_loss: 0.3313 - val_accuracy: 0.8824\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2572 - accuracy: 0.9028 - val_loss: 0.3047 - val_accuracy: 0.8903\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2558 - accuracy: 0.9008 - val_loss: 0.3005 - val_accuracy: 0.8901\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2506 - accuracy: 0.9042 - val_loss: 0.3309 - val_accuracy: 0.8839\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2455 - accuracy: 0.9056 - val_loss: 0.3039 - val_accuracy: 0.8871\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2471 - accuracy: 0.9047 - val_loss: 0.3194 - val_accuracy: 0.8857\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2386 - accuracy: 0.9081 - val_loss: 0.2976 - val_accuracy: 0.8950\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2331 - accuracy: 0.9098 - val_loss: 0.3281 - val_accuracy: 0.8843\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2324 - accuracy: 0.9110 - val_loss: 0.3244 - val_accuracy: 0.8867\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2282 - accuracy: 0.9117 - val_loss: 0.3183 - val_accuracy: 0.8895\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2276 - accuracy: 0.9120 - val_loss: 0.3053 - val_accuracy: 0.8942\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2249 - accuracy: 0.9122 - val_loss: 0.2992 - val_accuracy: 0.8953\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2173 - accuracy: 0.9158 - val_loss: 0.3124 - val_accuracy: 0.8928\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2170 - accuracy: 0.9166 - val_loss: 0.3013 - val_accuracy: 0.8938\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2118 - accuracy: 0.9181 - val_loss: 0.2907 - val_accuracy: 0.8945\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2101 - accuracy: 0.9196 - val_loss: 0.2971 - val_accuracy: 0.8946\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2074 - accuracy: 0.9187 - val_loss: 0.3295 - val_accuracy: 0.8838\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2067 - accuracy: 0.9199 - val_loss: 0.2963 - val_accuracy: 0.8958\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2024 - accuracy: 0.9215 - val_loss: 0.3156 - val_accuracy: 0.8962\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2010 - accuracy: 0.9217 - val_loss: 0.3047 - val_accuracy: 0.8966\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1954 - accuracy: 0.9238 - val_loss: 0.3182 - val_accuracy: 0.8939\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1969 - accuracy: 0.9237 - val_loss: 0.3167 - val_accuracy: 0.8958\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1919 - accuracy: 0.9256 - val_loss: 0.3035 - val_accuracy: 0.8992\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1908 - accuracy: 0.9266 - val_loss: 0.3141 - val_accuracy: 0.8971\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1894 - accuracy: 0.9260 - val_loss: 0.3000 - val_accuracy: 0.8947\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1866 - accuracy: 0.9266 - val_loss: 0.3136 - val_accuracy: 0.8963\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1852 - accuracy: 0.9295 - val_loss: 0.3262 - val_accuracy: 0.8914\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1791 - accuracy: 0.9295 - val_loss: 0.3212 - val_accuracy: 0.8937\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1791 - accuracy: 0.9297 - val_loss: 0.3186 - val_accuracy: 0.8988\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1776 - accuracy: 0.9312 - val_loss: 0.3216 - val_accuracy: 0.8996\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1799 - accuracy: 0.9301 - val_loss: 0.3051 - val_accuracy: 0.8989\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1745 - accuracy: 0.9318 - val_loss: 0.3162 - val_accuracy: 0.8997\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1766 - accuracy: 0.9309 - val_loss: 0.3282 - val_accuracy: 0.8965\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1692 - accuracy: 0.9343 - val_loss: 0.3127 - val_accuracy: 0.9006\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1691 - accuracy: 0.9336 - val_loss: 0.3371 - val_accuracy: 0.8924\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1678 - accuracy: 0.9342 - val_loss: 0.3449 - val_accuracy: 0.8935\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1676 - accuracy: 0.9334 - val_loss: 0.3360 - val_accuracy: 0.8978\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1654 - accuracy: 0.9360 - val_loss: 0.3230 - val_accuracy: 0.8972\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1620 - accuracy: 0.9371 - val_loss: 0.3293 - val_accuracy: 0.8987\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1623 - accuracy: 0.9376 - val_loss: 0.3360 - val_accuracy: 0.8949\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1611 - accuracy: 0.9371 - val_loss: 0.3323 - val_accuracy: 0.8995\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1584 - accuracy: 0.9383 - val_loss: 0.3267 - val_accuracy: 0.8979\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1573 - accuracy: 0.9380 - val_loss: 0.3513 - val_accuracy: 0.8957\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1560 - accuracy: 0.9391 - val_loss: 0.3277 - val_accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52446d4490>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h_5_66GM2gr"
      },
      "source": [
        "model.save('Lab07_model.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT_YNK8cNToq",
        "outputId": "464d87ac-0458-4a44-92d9-7ba4eb537b4d"
      },
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/Lab07.ipynb"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/Lab07.ipynb to html\n",
            "[NbConvertApp] Writing 295361 bytes to /content/Lab07.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}