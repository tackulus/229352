{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQnhhk93pPCZ0uZVn2lkKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tackulus/229352/blob/main/Lab06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUK5Xhf7y1cK"
      },
      "source": [
        "## **Lab 05**\n",
        "\n",
        "---\n",
        "\n",
        "> **229352 Statistical Learning for Data Science 2**\n",
        "\n",
        "> **Kasidis Torcharoen (610510531)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b2Rf4w_MGpj"
      },
      "source": [
        "%%capture\n",
        "!wget -O Lab06-X.csv \\\n",
        "    https://raw.githubusercontent.com/tackulus/229352/main/dataset/Lab06-X.csv\n",
        "!wget -O Lab06-y.csv \\\n",
        "    https://raw.githubusercontent.com/tackulus/229352/main/dataset/Lab06-y.csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvjvkkwNIHU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "X = pd.read_csv(\"Lab06-X.csv\", sep=' ', header=None).to_numpy()\n",
        "y = pd.read_csv(\"Lab06-y.csv\", sep=' ', header=None).to_numpy()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k887f6C4oo1t",
        "outputId": "b1b7f0d4-3001-441e-8797-39a1f6f76fa9"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlRlH5nqXm_p"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzXZc0O6PSBc"
      },
      "source": [
        "Xc = np.c_[ np.ones(len(X)), X]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68KZpJo_YHQJ"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M71GMHaZpct"
      },
      "source": [
        "start = time()\n",
        "\n",
        "eta, n, tol = 0.001, len(Xc), 0.001\n",
        "theta = np.zeros((Xc.shape[1], 1))\n",
        "while(1):\n",
        "    theta_1 = theta - eta * (1/n) * Xc.T.dot( np.dot(Xc, theta) - y )\n",
        "    if np.linalg.norm(theta_1 - theta) < tol:\n",
        "        break\n",
        "    else: theta = theta_1\n",
        "\n",
        "end = time()\n",
        "\n",
        "running_time = end - start\n",
        "theta_GD = theta_1.T"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ld9KIngqOys",
        "outputId": "1bd598fe-275a-4de7-db48-97b28cf613fb"
      },
      "source": [
        "running_time"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.4850735664367676"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT4GIwNAyH2T",
        "outputId": "4c31f2c4-a3a3-4211-e3f4-f93f5b3cedf4"
      },
      "source": [
        "theta_GD"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.96413787, 24.50293853, 38.12376351, 93.46615443, 42.41349621,\n",
              "        19.36312915, 30.00784032, 39.69470585, 53.37651679, 33.63541215,\n",
              "        70.6054717 , 18.29094536, 56.73303026, 55.02775656, 88.99983917,\n",
              "        35.84769953, 11.90618569, 97.02348822, 64.91044416, 65.54318164,\n",
              "        50.67950072, 47.651318  , 36.62315743, 54.29534381, 42.59175178,\n",
              "        22.85708346, 83.51706031, 49.49630905, 82.36761771, 49.98863399,\n",
              "        47.58711542, 42.81486958, 55.89948592,  6.78381683, 61.23787173,\n",
              "         7.28208088, 55.58679934, 48.58911465, 27.72991812, 42.46275684,\n",
              "        44.54757566, 90.66751564, 70.37990482, 43.83411674, 67.18171522,\n",
              "        83.49136373, 51.58866402, 13.93310305, 71.53169338, 70.75748335,\n",
              "        78.98906721, 57.9598426 , 35.79304282,  1.37395064, 89.1058799 ,\n",
              "        57.77203371, 57.32038403, 47.5404562 , 49.65925522, 11.07992401,\n",
              "        31.15280779, 45.01530933, 77.39393821, 95.59860387, 58.91203407,\n",
              "        78.1476001 , 24.29704081, 82.31746566, 40.55600907, 19.19062611,\n",
              "        36.49759526, 79.17739343, 46.52082456, 78.64635941,  5.38705679,\n",
              "        60.33284464, 62.34352737,  4.0052624 , 30.34647612, 29.13033696,\n",
              "        95.96263158, 74.16650734, 88.91741326, 73.37704606, 94.16829428,\n",
              "        17.70642856, 77.03968737, 38.05864233, 85.77405061, 78.15227852,\n",
              "        12.43642704,  1.81902024, 62.66494024, 95.35373394, 89.30831415,\n",
              "        86.37171231, 57.21151834, 22.40873078, 66.56333634, 81.06025955,\n",
              "        23.02598302, 82.50363479,  3.83917519, 24.88660778, 97.81426183,\n",
              "        45.34878705, 97.69582583, 21.4810148 , 51.48404008, 69.22653007,\n",
              "        77.1267323 , 80.80634451, 43.99195345, 98.95174889, 63.20347877,\n",
              "        88.30864224, 45.36958139, 56.97351741, 23.26658518, 11.86806016,\n",
              "        27.28228029, 77.52845875, 57.96896171,  9.31735993, 25.10698885,\n",
              "        67.32134344, 95.178583  , 76.21559094, 94.00538854, 77.8927462 ,\n",
              "        92.04622893, 35.8997438 , 35.76430011, 10.85871941, 64.9270092 ,\n",
              "        75.63842004, 65.97421798, 34.02239133, 83.3965272 , 40.26593491,\n",
              "        43.89790898, 71.40089471,  0.2638759 ,  1.13201613, 65.60175619,\n",
              "        21.02417391, 86.05041613, 18.85809261, 98.13365158, 72.82136135,\n",
              "         7.56099697, 23.87921957, 74.80904928, 71.89060964, 91.15896152,\n",
              "        51.40931456,  3.25005875, 96.023553  , 66.1858518 ,  9.01327145,\n",
              "        21.02508735, 87.47217876, 58.90516924, 92.61407354, 29.28913705,\n",
              "        34.97848308, 38.87035524, 47.31111362, 67.57701284, 24.22490264,\n",
              "        85.02572205, 62.36958304, 67.22385699, 81.63495609, 73.4189234 ,\n",
              "         3.74745414, 39.69176664, 36.113409  , 68.07228292, 99.55689832,\n",
              "        65.68660833, 39.6899277 ,  7.44438113, 46.61448312, 30.66040393,\n",
              "        91.17452207, 12.56445788, 65.16971618, 26.67969046, 73.39428502,\n",
              "        58.37242072, 10.19494158, 88.44725406, 95.93251318, 87.43102034,\n",
              "        79.45333559, 96.91447809, 78.65493993, 69.10116465, 15.57067433,\n",
              "        31.20873611,  8.50245086,  8.32874278, 38.72479044,  3.39900776,\n",
              "        18.79684355, 30.92969476, 43.39195842, 66.169726  ,  2.4528423 ,\n",
              "         1.96157508, 60.65405513,  1.31915192, 64.51741875,  5.04203259,\n",
              "        20.69810413, 86.97733726, 57.52120001, 28.0897886 , 42.06252784,\n",
              "        90.7217293 , 24.0602299 , 34.90733951, 47.28253703, 73.72436685,\n",
              "        44.16847737, 36.38491004, 74.45819753, 54.51691422, 56.36625063,\n",
              "        16.83509923, 72.15016206, 13.52564597, 46.81826655, 94.97424167,\n",
              "        89.20723274,  3.19298286, 85.01524313,  6.3270608 , 82.02726869,\n",
              "        17.56068906,  3.71573399, 24.10639149, 36.27129249, 49.46386329,\n",
              "        47.89463569,  0.8098763 , 72.91321053, 19.68680484, 57.37908073,\n",
              "        37.06293733, 69.7530359 , 70.94936733, 99.43841773,  2.64254824,\n",
              "         3.08127303, 70.98443562, 41.8343423 , 85.33935783, 19.9141418 ,\n",
              "        80.61916813, 98.48424563, 90.30230986, 32.02746129, 51.51660948,\n",
              "        15.88972557, 78.43813228,  2.8813434 , 48.5278144 ,  5.92033971,\n",
              "        43.60362461, 16.53956249,  6.27594506, 29.81777451, 81.28066245,\n",
              "        14.48592352, 91.17608742, 76.59334647, 94.89601798,  5.20686232,\n",
              "        10.11553423, 78.58445112, 54.73831244, 60.70487399,  1.19119148,\n",
              "        60.29658865, 47.65676286, 51.78054913, 37.04149101, 65.06509492,\n",
              "        15.85216143, 13.88694101, 11.27684573, 79.09137307, 92.08166839,\n",
              "        87.55113435,  8.2676943 , 37.95848039, 64.33780702,  7.00221371,\n",
              "        60.37523965]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s20TSdjkgggs"
      },
      "source": [
        "# Part 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgKfsqvbghh5",
        "outputId": "58696faa-fd2e-445d-abe5-4d5e2493dc7d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "clf = LinearRegression()\n",
        "clf.fit(X, y)\n",
        "theta_Skl = np.c_[clf.intercept_, clf.coef_]\n",
        "\n",
        "np.linalg.norm(theta_GD - theta_Skl)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.658387604090347"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpw1fhGwymyy"
      },
      "source": [
        "> The $\\theta_{GD}$ is close to $\\theta_{Skl}$ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEHGC0sdkprR"
      },
      "source": [
        "# Part 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pEkRm5MiJv8"
      },
      "source": [
        "start = time()\n",
        "\n",
        "eta, tol = 0.001, 0.001\n",
        "theta = np.zeros((Xc.shape[1]))\n",
        "Xs = np.copy(Xc)\n",
        "np.random.shuffle(Xs)\n",
        "\n",
        "while(1):\n",
        "    theta_pre = np.copy(theta)\n",
        "    for i in range(1):\n",
        "        theta = theta - eta * Xs[i,:] * ( np.dot(Xs[i,:], theta) - y[i] )\n",
        "    \n",
        "    if np.linalg.norm(theta - theta_pre) < tol: break\n",
        "\n",
        "end = time()\n",
        "\n",
        "running_time = end - start\n",
        "theta_SGD = theta.T"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YolvKiR_xzu0",
        "outputId": "069bef76-c764-4728-f59c-f377da75f50e"
      },
      "source": [
        "running_time"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.007703542709350586"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfopR2zCx8sD",
        "outputId": "8034d8ed-84a1-4daf-f9d1-0dcb0e13a21a"
      },
      "source": [
        "theta_SGD"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.24472259, -1.40115411, -0.4947146 ,  0.51501363, -1.96400323,\n",
              "       -1.00748686,  1.94139512,  4.98175829,  0.79067905,  2.50130911,\n",
              "       -5.0623221 ,  3.98229729, -0.37178008,  4.66162668, -3.23067758,\n",
              "        3.32232186,  0.24744075,  2.26848759, -3.45967949, -2.14785949,\n",
              "        2.53863265, -1.39662292, -0.26866814, -0.70091073,  3.88238505,\n",
              "       -1.00046134,  7.84843467,  6.9783781 ,  3.40735492, -1.38862034,\n",
              "       -3.52439423, -3.65075614,  2.29515839,  2.15035136,  2.7938964 ,\n",
              "       -2.0112973 ,  1.76441731,  0.17067961,  1.92025653, -7.03923182,\n",
              "       -4.99132862,  2.06467587,  4.34293758, -3.43470889,  2.74218696,\n",
              "        0.88349639,  1.74585035,  0.91581341, -6.36427872, -3.54947701,\n",
              "       -3.93567269,  3.88523346, -3.40796147, -4.59325787,  2.17523347,\n",
              "       -0.7704551 ,  3.53089422, -3.71166593,  0.94493365,  2.91034934,\n",
              "       -3.15439148,  2.93462428,  1.03871169,  0.28149258,  1.05038412,\n",
              "        5.09262939,  0.64411092, -0.34718746, -0.83318033,  2.46179717,\n",
              "       -0.33666095,  2.57970214, -0.5276913 , -7.2108007 , -4.39011104,\n",
              "        1.52904517,  3.29915141,  0.28191352, -4.81634666,  4.91942598,\n",
              "        2.90325716, -0.10524041, -0.81880825,  1.90703944, -0.73181227,\n",
              "        2.38494335,  0.83682831, -4.83748449,  1.88995669, -4.02321987,\n",
              "       -1.11278047,  7.01112931,  0.43044355,  3.19474943,  5.03658395,\n",
              "       -1.12584345, -4.79779482, -4.10501471,  5.21574825,  1.47001424,\n",
              "       -1.95198808,  6.06045308,  0.80654432, -1.50416625,  1.16823265,\n",
              "        3.85838215,  4.47830321, -0.75177431, -0.94247919,  0.17851814,\n",
              "       -0.13873135, -3.09958208,  6.41754925, -3.40377725, -0.70361141,\n",
              "       -0.90366439, -3.28592919, -3.5165486 ,  1.43867868,  2.5597422 ,\n",
              "        0.95006429, -0.52044929,  2.16708873, -2.03294484, -0.18207608,\n",
              "        0.52830149,  0.34763269, -2.47220405,  1.65306985,  6.19022876,\n",
              "        2.26823007, -0.90362724, -4.29677368,  1.367557  , -0.11540174,\n",
              "       -3.08012082,  2.09222026,  4.32846959,  0.05900964,  3.87134467,\n",
              "       -0.96324304,  1.10184253,  0.22483311, -1.55949213,  0.24119408,\n",
              "       -1.39586463, -2.45904691, -0.94388479,  0.99545396, -2.77320515,\n",
              "       -5.10682806,  4.56768001, -1.79544078,  3.25507045, -0.59939967,\n",
              "        1.65463027, -4.40934342, -2.97588262,  3.12032582, -7.28168688,\n",
              "        0.91372933, -0.44761425, -0.08213135, -0.81778631, -0.74917271,\n",
              "       -3.25167806,  1.06916764, -2.2648309 , -3.51510215, -1.20897981,\n",
              "       -3.60542759,  2.77622024, -4.37439016,  1.95217694, -0.53615077,\n",
              "       -0.54375579,  4.33949442,  1.66755656, -0.5319109 , -2.56566124,\n",
              "       -4.11346378, -1.77520325, -4.59638722, -0.30707202,  2.3449715 ,\n",
              "       -3.62468746,  3.46310429, -5.03827879, -3.18902419, -6.68864698,\n",
              "        5.53988642,  1.35468457,  5.6294605 ,  5.07576872, -5.97302564,\n",
              "       -0.6461777 ,  2.01905361,  0.42059233, -6.73750999,  4.78119766,\n",
              "        0.33898389, -0.98752485,  1.0954015 , -3.00129211, -3.25740283,\n",
              "        0.41093157,  0.08716671, -0.81542792,  3.51173447,  4.19813287,\n",
              "        1.32364752, -5.12215463,  1.65746769, -1.58011502,  0.1546958 ,\n",
              "       -1.60554492,  1.62954482,  4.83903181,  2.91054749,  0.7904063 ,\n",
              "        4.51158163, -3.88805333,  4.70834787, -1.45428594,  8.66614956,\n",
              "       -0.96132162, -1.96080305,  2.99234532,  4.02472106, -0.47377127,\n",
              "       -0.50454105,  3.86877139,  1.60147158,  0.97341346,  1.94423274,\n",
              "       -1.21832486,  1.51089391, -1.23144178, -1.28010932, -6.38055995,\n",
              "        1.34530732,  3.69960527,  2.22727536,  2.43983898, -0.47382342,\n",
              "       -4.89013546,  1.77034318, -2.04590061, -5.45352625, -1.92214393,\n",
              "       -1.51110812,  0.61145243,  2.82049585,  2.71894272, -3.21561038,\n",
              "       -4.25119245,  0.29802101,  0.43261875,  1.64453603,  4.8444673 ,\n",
              "       -2.90915581,  2.49901454, -2.14824262,  0.85232357,  2.18632921,\n",
              "        0.55867106, -3.65891362,  2.12024863, -2.77966533,  2.27372923,\n",
              "       -3.62648747, -2.71913759, -0.20971806,  4.41079347,  2.9977494 ,\n",
              "        1.27943134, -4.35131652, -3.565114  , -0.49560426,  1.56269209,\n",
              "       -3.20475723, -6.49213606,  0.79096477, -0.06327348,  7.29804814,\n",
              "        4.97468766,  2.31187188,  2.1563068 ,  2.14102536,  3.74665284,\n",
              "       -1.69981813,  0.77445813,  1.44771416,  5.92789291, -1.8616623 ,\n",
              "       -0.97676343,  1.27379369, -2.02595493,  2.20686603,  4.49168325,\n",
              "       -2.47221369])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1KOqAJjqY0j",
        "outputId": "a8b500cb-f46a-417e-bdcc-80291e6da27f"
      },
      "source": [
        "np.linalg.norm(theta_SGD - theta_Skl)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1008.5011792171015"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae761zrdy4kq"
      },
      "source": [
        "> The $\\theta_{SGD}$ is not close to $\\theta_{Skl}$ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjLrnTpeyYE3"
      },
      "source": [
        "# Part 5\n",
        "\n",
        "> Some advantages of batch gradient descent are its computational efficient, it produces a stable error gradient and a stable convergence. Some disadvantages are the stable error gradient can sometimes result in a state of convergence that isnâ€™t the best the model can achieve. It also requires the entire training dataset be in memory and available to the algorithm.\n",
        "\n",
        "> One advantage of stochastic gradient descent is the frequent updates allow us to have a pretty detailed rate of improvement.\n",
        "The frequent updates, however, are more computationally expensive than the batch gradient descent approach. Additionally, the frequency of those updates can result in noisy gradients, which may cause the error rate to jump around instead of slowly decreasing."
      ]
    }
  ]
}