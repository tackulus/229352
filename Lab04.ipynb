{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUH33RhTXUmAANTMbmy9yF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tackulus/229352/blob/main/Lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoCtgQX5x6PK"
      },
      "source": [
        "## **Lab 03**\n",
        "\n",
        "---\n",
        "\n",
        "> **229352 Statistical Learning for Data Science 2**\n",
        "\n",
        "> **Kasidis Torcharoen (610510531)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2KR1Grmzph7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets \n",
        "mnist = datasets.load_digits()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVOvHFW8xpN5"
      },
      "source": [
        "**First, normalized the dataset to avoid numeric overflow.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b5q2lf6z5eH"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(mnist.data)\n",
        "y = mnist.target"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im4Pd64Vxo8G"
      },
      "source": [
        "**Then perform the following experiments:**\n",
        "\n",
        "**1. In the first experiment, we will compare run time of the primal and dual optimization problems in S**\n",
        "\n",
        "> **(a) For k ∈ {0, 5, 10, 15, 20, 25}, remove the first and the last k columns (features) from the dataset and perform the following steps:**\n",
        "\n",
        "> **(b) Train an SVM model using sklearn.svm.LinearSVC method twice: one using the primal form and another using the dual form. This can be done by setting the model’s parameter dual to False and True, respectively. Also, set the max_iter parameter (maximum number of optimization steps) to be 10^7 to prevent any convergence warning**\n",
        "\n",
        "> **(c) Measure the training times of both primal and dual form SVM. To measure the elapsed time in Python.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "netDVujZs_Ma"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from time import time\n",
        "\n",
        "primal, dual = {}, {}\n",
        "for k in range(0, 26, 5):\n",
        "    if k == 0: Xk = X\n",
        "    else: Xk = X[:, k:-k]\n",
        "    for timer, b in zip([primal, dual], [False, True]):\n",
        "        clf = LinearSVC( dual=b, max_iter=10**7 )\n",
        "        start = time()\n",
        "        clf.fit(Xk, y)\n",
        "        end = time()\n",
        "        timer[ X.shape[1] - 2 * k ] = end - start"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4otPU7BbzEgo"
      },
      "source": [
        "**After you have done the above steps for all k, make plots of “# of features” vs “training time” for the primal form and the dual form. If someone asks you whether they should use the primal or dual form to train on their data, what would your answer be?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjY7_FdWzIYc"
      },
      "source": [
        "**2. In the second experiment, we will study the relationships between the support vectors, the primal coefficient (w) and the dual coefficient (αi) in an SVM model.**\n",
        "\n",
        "> **(a) From the (normalized) mini MNIST dataset, pick any two labels and train an SVM model using sklearn.svm.SVC on the data with those two labels.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62JhZ78QzQzy"
      },
      "source": [
        "> **(b) How many support vectors does your model have? You can check the list of all support vectors by calling the attribute support vectors from your trained model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awpXXAfgzXUE"
      },
      "source": [
        "> **(c) What is the relationship between the hyperparameter C and the number of support vectors? You might want to start with a small value of C such as 0.001. Can you give an explanation for this relationship?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7VNtffGxddW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}